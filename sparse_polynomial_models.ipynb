{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea4e7f9",
   "metadata": {},
   "source": [
    "# Sparse Polynomial Regression (degree â‰¤ 6)\n",
    "\n",
    "This notebook fits a noisy dataset generated from a **sparse polynomial** (terms up to $x^6$).\n",
    "We compare:\n",
    "- Polynomial regression without regularisation\n",
    "- Ridge regression (L2)\n",
    "- Lasso regression (L1)\n",
    "\n",
    "We split data into train/validation/test and tune hyperparameters using validation MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset (same folder as this notebook)\n",
    "path = 'random_poly_21.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "X = df[[df.columns[0]]].values  # x\n",
    "y = df[df.columns[1]].values    # y\n",
    "\n",
    "# Train/Val/Test split (60/20/20)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print('Sizes:', len(X_train), len(X_val), len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: polynomial pipeline (degree 6)\n",
    "degree = 6\n",
    "\n",
    "def make_pipe(model):\n",
    "    return Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "def validation_mse(pipe):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    return mean_squared_error(y_val, pipe.predict(X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1589b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Polynomial regression (no regularisation)\n",
    "lin_pipe = make_pipe(LinearRegression())\n",
    "lin_val_mse = validation_mse(lin_pipe)\n",
    "print('Poly (no reg) validation MSE:', lin_val_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1096eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Ridge regression: tune alpha on validation set\n",
    "ridge_alphas = np.logspace(-6, 3, 40)\n",
    "ridge_scores = []\n",
    "\n",
    "for a in ridge_alphas:\n",
    "    pipe = make_pipe(Ridge(alpha=a, random_state=42))\n",
    "    ridge_scores.append((a, validation_mse(pipe)))\n",
    "\n",
    "ridge_scores = np.array(ridge_scores, dtype=float)\n",
    "best_ridge_alpha = ridge_scores[np.argmin(ridge_scores[:, 1]), 0]\n",
    "print('Best Ridge alpha:', best_ridge_alpha)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ridge_scores[:, 0], ridge_scores[:, 1], marker='o', markersize=3)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Ridge alpha')\n",
    "plt.ylabel('Validation MSE')\n",
    "plt.title('Ridge: validation MSE vs alpha')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Lasso regression: tune alpha on validation set\n",
    "lasso_alphas = np.logspace(-6, 0, 40)\n",
    "lasso_scores = []\n",
    "\n",
    "for a in lasso_alphas:\n",
    "    pipe = make_pipe(Lasso(alpha=a, max_iter=200000, random_state=42))\n",
    "    lasso_scores.append((a, validation_mse(pipe)))\n",
    "\n",
    "lasso_scores = np.array(lasso_scores, dtype=float)\n",
    "best_lasso_alpha = lasso_scores[np.argmin(lasso_scores[:, 1]), 0]\n",
    "print('Best Lasso alpha:', best_lasso_alpha)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lasso_scores[:, 0], lasso_scores[:, 1], marker='o', markersize=3)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Lasso alpha')\n",
    "plt.ylabel('Validation MSE')\n",
    "plt.title('Lasso: validation MSE vs alpha')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f64d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit best models on train+val and evaluate on the held-out test set\n",
    "X_trainval = np.vstack([X_train, X_val])\n",
    "y_trainval = np.concatenate([y_train, y_val])\n",
    "\n",
    "best_lin = make_pipe(LinearRegression()).fit(X_trainval, y_trainval)\n",
    "best_ridge = make_pipe(Ridge(alpha=float(best_ridge_alpha), random_state=42)).fit(X_trainval, y_trainval)\n",
    "best_lasso = make_pipe(Lasso(alpha=float(best_lasso_alpha), max_iter=200000, random_state=42)).fit(X_trainval, y_trainval)\n",
    "\n",
    "def report(name, model):\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, pred)\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    print(f'{name}: Test MSE={mse:.6f}, Test R2={r2:.4f}')\n",
    "\n",
    "report('Poly (no reg)', best_lin)\n",
    "report('Ridge', best_ridge)\n",
    "report('Lasso', best_lasso)\n",
    "\n",
    "# Plot fitted curves with data\n",
    "xx = np.linspace(X.min(), X.max(), 400).reshape(-1, 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_train, y_train, label='Train')\n",
    "plt.scatter(X_val, y_val, label='Val')\n",
    "plt.scatter(X_test, y_test, label='Test')\n",
    "plt.plot(xx, best_lin.predict(xx), label='Poly (no reg)')\n",
    "plt.plot(xx, best_ridge.predict(xx), label='Ridge')\n",
    "plt.plot(xx, best_lasso.predict(xx), label='Lasso')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Degree-6 polynomial fits')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea11592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate polynomial coefficients (choose the most appropriate model)\n",
    "# Choose Ridge for stable coefficient estimates under correlated polynomial features.\n",
    "chosen = best_ridge\n",
    "\n",
    "poly = chosen.named_steps['poly']\n",
    "scaler = chosen.named_steps['scaler']\n",
    "model = chosen.named_steps['model']\n",
    "\n",
    "terms = poly.get_feature_names_out(['x'])\n",
    "\n",
    "# Unscale coefficients back into original polynomial feature space:\n",
    "# y = w_scaled * ((phi - mean)/std) + b_scaled\n",
    "# => y = (w_scaled/std)*phi + (b_scaled - sum(w_scaled*mean/std))\n",
    "w_scaled = model.coef_\n",
    "b_scaled = model.intercept_\n",
    "\n",
    "w = w_scaled / scaler.scale_\n",
    "b = b_scaled - np.sum(w_scaled * scaler.mean_ / scaler.scale_)\n",
    "\n",
    "coef_table = pd.DataFrame({'term': terms, 'coef': w})\n",
    "coef_table.loc[len(coef_table)] = ['intercept', b]\n",
    "print(coef_table)\n",
    "\n",
    "plt.figure()\n",
    "mask = coef_table.term != 'intercept'\n",
    "plt.bar(coef_table.loc[mask, 'term'], coef_table.loc[mask, 'coef'])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Estimated coefficient')\n",
    "plt.title('Estimated polynomial coefficients (Ridge)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
